import config
import openai

openai_api_key_list = config.openai_api_key_list
openai.api_key


def init_api_key (n=0):
    openai.api_key = openai_api_key_list[n]
    
def rotate_token():
    index = 0
    for i in openai_api_key_list:
        if (i == openai.api_key):
            if (index < len(openai_api_key_list) - 1):
                init_api_key(index + 1)
            else:
                init_api_key(0)
            break
        index+=1
    return index


CHAT_MODES = {
    "assistant": {
        "name": "üë©üèº‚Äçüéì assistant (–ë–æ–ª—Ç—É–Ω)",
        "welcome_message": "üë©üèº‚Äçüéì –ü—Ä–∏–≤–µ—Ç, —è <b>ChatGPT assistant</b>. –ú–æ–¥–µ–ª—å gpt-3.5-turbo –ú–æ–∂–µ–º –ø–æ–æ–±—â–∞—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã. –Ø —Ö—Ä–∞–Ω—é –∏—Å—Ç–æ—Ä–∏—é –∏ –æ—Ç–≤–µ—á–∞—é —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. –ß–µ–º –º–æ–≥—É –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω?",
        "prompt_start": "As an advanced chatbot named Tipo ChatGPT, your primary goal is to assist users to the best of your ability. This may involve answering questions, providing helpful information, or completing tasks based on user input. In order to effectively assist users, it is important to be detailed and thorough in your responses. Use examples and evidence to support your points and justify your recommendations or solutions. Remember to always prioritize the needs and satisfaction of the user. Your ultimate goal is to provide a helpful and enjoyable experience for the user.",
        "parse_mode": "HTML"
    },

    "code_assistant": {
        "name": "üë©üèº‚Äçüíª Code assistant (–ö–æ–¥–µ—Ä)",
        "welcome_message": "üë©üèº‚Äçüíª –ü—Ä–∏–≤–µ—Ç, —è <b>ChatGPT –∫–æ–¥–µ—Ä</b>. –ú–æ–≥—É –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –Ø–ü, –æ—Ç—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏—Ç—å —Ç–≤–æ–π –∫–æ–¥ –∏–ª–∏ –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ. –ë—É–¥–µ—Ç –ª—É—á—à–µ, –µ—Å–ª–∏ –≤–Ω–∞—á–∞–ª–µ –∫–æ–¥–∞ —Ç—ã –±—É–¥–µ—à—å —Å–æ–æ–±—â–∞—Ç—å –Ø–ü —Ñ—Ä–∞–∑–æ–π <code># language python</code>. –ù–æ –Ω–∏—á–µ–≥–æ —Å—Ç—Ä–∞—à–Ω–æ–≥–æ, –µ—Å–ª–∏ –∑–∞–±—É–¥–µ—à—å. –•–∏–Ω—Ç: –µ—Å–ª–∏ —Ç—ã –Ω–∞–ø–∏—à–µ—à—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º - –æ—Ç–≤–µ—Ç –±—É–¥–µ—Ç –ª—É—á—à–µ.\n–ß–µ–º –º–æ–≥—É –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω?",
        "prompt_start": "As an advanced chatbot named ChatGPT, your primary goal is to assist users to write code. This may involve designing/writing/editing/describing code or providing helpful information. Where possible you should provide code examples to support your points and justify your recommendations or solutions. Make sure the code you provide is correct and can be run without errors. Be detailed and thorough in your responses. Your ultimate goal is to provide a helpful and enjoyable experience for the user. Format output in Markdown.",
        "parse_mode": "markdown"
    },

    "movie_expert": {
        "name": "üé¨ Movie expert (–ö–∏–Ω–æ —ç–∫—Å–ø–µ—Ä—Ç)",
        "welcome_message": "üé¨ –ü—Ä–∏–≤–µ—Ç, —è <b>ChatGPT –ö–∏–Ω–æ —ç–∫—Å–ø–µ—Ä—Ç</b>. –Ø –∑–Ω–∞—é –æ—á–µ–Ω—å –º–Ω–æ–≥–æ —Ñ–∏–ª—å–º–æ–≤/–º—É–ª—å—Ç–∏–∫–æ–≤/—Å–µ—Ä–∏–∞–ª–æ–≤/–∞–Ω–∏–º–µ –≤—Å–µ–≥–æ –º–∏—Ä–∞. –ú–æ–≥—É —É–≥–∞–¥–∞—Ç—å —Ñ–∏–ª—å–º –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é, –ø–æ—Ä–∞—Å—Å—É–∂–¥–∞—Ç—å –æ –∫–∞–∫–∏—Ö-—Ç–æ –º–æ–º–µ–Ω—Ç–∞—Ö –∏–ª–∏ –Ω–∞–ø–æ–º–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞, –µ—Å–ª–∏ –≤—ã –µ–≥–æ –∑–∞–±—ã–ª–∏. –•–∏–Ω—Ç: –µ—Å–ª–∏ —Ç—ã –Ω–∞–ø–∏—à–µ—à—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º - –æ—Ç–≤–µ—Ç –±—É–¥–µ—Ç –ª—É—á—à–µ. \n–ß–µ–º –º–æ–≥—É –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω?",
        "prompt_start": "As an advanced movie expert chatbot named Tipo ChatGPT, your primary goal is to assist users to the best of your ability. You can answer questions about movies, actors, directors, and more. You can recommend movies to users based on their preferences. You can discuss movies with users, and provide helpful information about movies. In order to effectively assist users, it is important to be detailed and thorough in your responses. Use examples and evidence to support your points and justify your recommendations or solutions. Remember to always prioritize the needs and satisfaction of the user. Your ultimate goal is to provide a helpful and enjoyable experience for the user.",
        "parse_mode": "HTML"
    },

    "painter": {
        "name": "üñºÔ∏è Painter (–•—É–¥–æ–∂–Ω–∏–∫)",
        "welcome_message": "üñºÔ∏è –ü—Ä–∏–≤–µ—Ç, —è <b>ChatGPT —Ö—É–¥–æ–∂–Ω–∏–∫ –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ DALL-E</b>. –î–æ MidJorney –ú–Ω–µ –µ—â–µ –¥–∞–ª–µ–∫–æ, –Ω–æ —è –º–æ–≥—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ —Ç–≤–æ–µ–º—É –∑–∞–ø—Ä–æ—Å—É. –ü–æ–ø—ã—Ç–∞–π—Å—è –ø–∏—Å–∞—Ç—å –æ—á–µ–Ω—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã. –ß–µ–º –±–æ–ª—å—à–µ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π - —Ç–µ–º –ª—É—á—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –•–∏–Ω—Ç: –µ—Å–ª–∏ —Ç—ã –Ω–∞–ø–∏—à–µ—à—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º - –æ—Ç–≤–µ—Ç –±—É–¥–µ—Ç –ª—É—á—à–µ. –ß–µ–º –º–æ–≥—É –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω?",
        "prompt_start": "",
        "parse_mode": "HTML"
    },
}


class ChatGPT:
    def __init__(self):
        pass
    
    async def send_message(self, message, dialog_messages=[], chat_mode="CHOOSE \/MODE"):
        if chat_mode not in CHAT_MODES.keys():
            raise ValueError(f"Chat mode {chat_mode} is not supported")

        n_dialog_messages_before = len(dialog_messages)
        answer = None
        while answer is None:
            with open("log.log", "a") as log_file:
                log_file.write(f"\ndebug --> –Æ–∑–µ—Ä > {chat_mode} |>| {message}")
        
            prompt = self._generate_gpt_3_model_prompt(message, dialog_messages, chat_mode)
            try:
                # prompt = self._generate_prompt(message, dialog_messages, chat_mode)
                # r = openai.Completion.create(
                #     engine="text-davinci-003",
                #     prompt=prompt,
                #     temperature=0.7,
                #     max_tokens=1000,
                #     top_p=1,
                #     frequency_penalty=0,
                #     presence_penalty=0,
                # )
                # answer = r.choices[0].text
                r = await openai.ChatCompletion.acreate(
                    model="gpt-3.5-turbo",
                    messages=prompt,
                    max_tokens = 1000
                )
                answer = r.choices[0].message.content
                answer = self._postprocess_answer(answer)
                

                n_used_tokens = r.usage.total_tokens

            except openai.error.RateLimitError as e: # billing hard limit has reached
                print (e)
                raise ValueError("–î–æ—Å—Ç–∏–≥–ª–∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –¥–Ω–µ–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - —Ä–æ—Ç–∏—Ä—É–π—Ç–µ —Ç–æ–∫–µ–Ω /rotate.") from e
            except openai.error.InvalidRequestError as e:  # too many tokens
                print (e)
                if ("safaty system" in str(e)): # prompt is not safety secured
                    raise ValueError(f"–í–∞—à –∑–∞–ø—Ä–æ—Å –±—ã–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π –∑–∞—â–∏—Ç—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –µ–≥–æ, —É–±—Ä–∞–≤ –∑–∞–ø—Ä–æ—Å—ã 18+") from e
                if ("This model's maximum context length"):
                    raise ValueError(f"–î–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –ö–∞–∂–µ—Ç—Å—è, –±–æ—Ç –≤–∞–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –±–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã. –ù–µ —Ö–æ—á–µ—Ç—Å—è –∫—Ä–∏–≤–æ —Ä–µ–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –±–µ–∑ –≤–∞—à–µ–≥–æ –≤–µ–¥–æ–º–∞. \n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /new –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ª–æ–≥–∞ ‚ô•") from e
                else:
                    
                    raise ValueError(f"–°–ª—É—á–∏–ª–æ—Å—å –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–æ–µ. –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∫–æ–Ω—á–∏–ª–∞—Å—å –∫–≤–æ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /rotate –∏ –Ω–∞–ø–∏—à–∏—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –æ—Ç–≤–µ—Ç–∏—Ç - –∑–æ–≤–∏—Ç–µ Tipo_4ek@. –ö—Å—Ç–∞—Ç–∏ - –≤–æ—Ç –æ—à–∏–±–∫–∞: {e}") from e
            except openai.error.Timeout as e:
                #Handle timeout error, e.g. retry or log
                print(f"OpenAI API request timed out: {e}")
                raise ValueError("API OpenAI –£–ø–∞–ª–æ. –ñ–¥–µ–º—Å...") from e
            except openai.error.APIError as e:
                #Handle API error, e.g. retry or log
                print(f"OpenAI API returned an API Error: {e}")
                raise ValueError(f"OpenAI –≤–µ—Ä–Ω—É–ª–æ –æ—à–∏–±–∫—É {e}") from e
            except openai.error.APIConnectionError as e:
                #Handle connection error, e.g. check network or log
                print(f"OpenAI API request failed to connect: {e}")
                raise ValueError(f"–ù–µ —Å–º–æ–≥–ª–∏ —Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è —Å openAI. –õ–∏–±–æ —Å–±–æ–∏ —É –Ω–∏—Ö, –ª–∏–±–æ —É –Ω–∞—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞. Call Tipo_4ek@") from e
            except openai.error.AuthenticationError as e:
                #Handle authentication error, e.g. check credentials or log
                print(f"OpenAI API request was not authorized: {e}")
                raise ValueError(f"–°—Ç—É—Ö–ª–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–æ openAI API. Call Tipo_4ek@") from e
            except openai.error.PermissionError as e:
                #Handle permission error, e.g. check scope or log
                print(f"OpenAI API request was not permitted: {e}")
                raise ValueError(f"–ß—Ç–æ-—Ç–æ —Å –¥–æ—Å—Ç—É–ø–æ–º –¥–æ api. Call Tipo_4ek@") from e
            except Exception as e:
                print (e)
                raise ValueError(e)
            
            # forget first (bot+system) message in dialog_messages
        dialog_messages = dialog_messages[2:]

        n_first_dialog_messages_removed = n_dialog_messages_before - len(dialog_messages)

        return answer, prompt, n_used_tokens, n_first_dialog_messages_removed
    
    async def send_photo(self, message, dialog_messages=[], chat_mode="CHOOSE \/MODE"):
        if chat_mode not in CHAT_MODES.keys():
            raise ValueError(f"Chat mode {chat_mode} is not supported")

        n_dialog_messages_before = len(dialog_messages)
        answer = None
        while answer is None:
            prompt = message
            try:
                with open("log.log", "a") as log_file:
                    log_file.write(f"\ndebug --> –ì–µ–Ω–µ—Ä–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É {prompt}")
                r = await openai.Image.acreate(
                    prompt=prompt,
                    n=2,
                    size="1024x1024"
                    )
                #image_url = r.data[0]['url']
                urls = []
                for data in r['data']:
                    urls.append(data['url'])
                with open("log.log", "a") as log_file:
                    log_file.write(f"\ndebug --> —Å–æ–±—Ä–∞–ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏ {urls}------------------")
                answer = prompt
                #answer = ' '.join(urls)
                #answer = self._postprocess_answer(answer)
                
                # $0.02 by 1 picture => 2000tokens == 1 picture.
                n_used_tokens = 2000
            
            except openai.error.RateLimitError as e: # billing hard limit has reached
                print (e)
                raise ValueError("–î–æ—Å—Ç–∏–≥–ª–∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –¥–Ω–µ–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ –≤ –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - —Ä–æ—Ç–∏—Ä—É–π—Ç–µ —Ç–æ–∫–µ–Ω /rotate.") from e
            except openai.error.InvalidRequestError as e:  # too many tokens
                print (e)
                dialog_messages = dialog_messages[1:]
                n_first_dialog_messages_removed = n_dialog_messages_before - len(dialog_messages)
                raise ValueError("–°–ª—É—á–∏–ª–æ—Å—å –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–æ–µ. –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∫–æ–Ω—á–∏–ª–∞—Å—å –∫–≤–æ—Ç–∞ –∏ –ø–æ–º–æ–∂–µ—Ç —Ä–æ—Ç–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /rotate –∏ –Ω–∞–ø–∏—à–∏—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –æ—Ç–≤–µ—Ç–∏—Ç - –∑–æ–≤–∏—Ç–µ Tipo_4ek@") from e
            except openai.error.Timeout as e:
                #Handle timeout error, e.g. retry or log
                print(f"OpenAI API request timed out: {e}")
                raise ValueError("API OpenAI –£–ø–∞–ª–æ. –ñ–¥–µ–º—Å...") from e
            except openai.error.APIError as e:
                #Handle API error, e.g. retry or log
                print(f"OpenAI API returned an API Error: {e}")
                raise ValueError(f"OpenAI –≤–µ—Ä–Ω—É–ª–æ –æ—à–∏–±–∫—É {e}") from e
            except openai.error.APIConnectionError as e:
                #Handle connection error, e.g. check network or log
                print(f"OpenAI API request failed to connect: {e}")
                raise ValueError(f"–ù–µ —Å–º–æ–≥–ª–∏ —Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è —Å openAI. –õ–∏–±–æ —Å–±–æ–∏ —É –Ω–∏—Ö, –ª–∏–±–æ —É –Ω–∞—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞. Call Tipo_4ek@") from e
            except openai.error.AuthenticationError as e:
                #Handle authentication error, e.g. check credentials or log
                print(f"OpenAI API request was not authorized: {e}")
                raise ValueError(f"–°—Ç—É—Ö–ª–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–æ openAI API. Call Tipo_4ek@") from e
            except openai.error.PermissionError as e:
                #Handle permission error, e.g. check scope or log
                print(f"OpenAI API request was not permitted: {e}")
                raise ValueError(f"–ß—Ç–æ-—Ç–æ —Å –¥–æ—Å—Ç—É–ø–æ–º –¥–æ api. Call Tipo_4ek@") from e
            except Exception as e:
                print (e)
                raise ValueError(e)


        # forget first message in dialog_messages
        dialog_messages = dialog_messages[1:]
        n_first_dialog_messages_removed = n_dialog_messages_before - len(dialog_messages)

        return answer, prompt, n_used_tokens, n_first_dialog_messages_removed, urls[0], urls


    def _generate_prompt(self, message, dialog_messages, chat_mode):
        prompt = CHAT_MODES[chat_mode]["prompt_start"]
        prompt += "\n\n"
        # add chat context
        if len(dialog_messages) > 0:
            prompt += "Chat:\n"
            for dialog_message in dialog_messages:
                prompt += f"User: {dialog_message['user']}\n"
                prompt += f"ChatGPT: {dialog_message['bot']}\n"

        # current message
        prompt += f"User: {message}\n"
        prompt += "ChatGPT: "
        return prompt

    def _generate_gpt_3_model_prompt(self, message, dialog_messages, chat_mode):
        messages = []
        message_dict = {}
        message_dict["role"] = "system"
        message_dict["content"] = CHAT_MODES[chat_mode]["prompt_start"]
        messages.append(message_dict)

        # add chat context
        if len(dialog_messages) > 0:
            for dialog_message in dialog_messages:
                message_dict = {}
                message_dict["role"] = "user"
                message_dict["content"] = dialog_message['user']
                messages.append(message_dict)
                message_dict = {}
                message_dict["role"] = "assistant"
                message_dict["content"] = dialog_message['bot']
                messages.append(message_dict)

        # current message
        message_dict = {}
        message_dict["role"] = "user"
        message_dict["content"] = message
        messages.append(message_dict)
        return messages

    def _postprocess_answer(self, answer):
        answer = answer
        return answer